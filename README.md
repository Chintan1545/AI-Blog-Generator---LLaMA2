# AI Blog Generator using LLaMA2

An AI-powered blog generation application built with Streamlit, LangChain, and LLaMA 2 running locally using CTransformers. This project generates blogs based on topic, word count, and target audience without relying on paid APIs.

## ğŸš€ Features
- ğŸ§  Local LLaMA 2 model inference (No API key required)
- âœï¸ Blog generation with customizable:
  - Topic
  - Number of words
  - Writing style (Researchers, Data Scientist, Common People)
- âš¡ Fast inference with model caching
- ğŸ–¥ï¸ Simple & interactive Streamlit UI
- ğŸ”’ Fully offline & privacy-friendly
- ğŸ”® Ready for future RAG & embedding integration

## ğŸ—ï¸ Tech Stack
- Python 3.9+
- Streamlit â€“ Frontend UI
- LangChain â€“ Prompt orchestration
- CTransformers â€“ Local LLM inference
- LLaMA 2 (GGML / GGUF) â€“ Language Model
- Sentence-Transformers â€“ Embeddings (for future RAG)

## ğŸ“‚ Project Architecture

```bash
AI-Blog-Generator/
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ llama-2-7b-chat.ggmlv3.q8_0.bin   # LLaMA 2 model file
â”‚
â”œâ”€â”€ app.py                               # Streamlit application
â”œâ”€â”€ requirements.txt                    # Project dependencies
â”œâ”€â”€ README.md                            # Project documentation
â””â”€â”€ .gitignore                           # Ignored files & folders
```

## âš™ï¸ Installation & Setup

1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/ai-blog-generator.git
cd ai-blog-generator
```
2ï¸âƒ£ Create Virtual Environment (Recommended)
```bash
conda create -n ai_blog_env python=3.9 -y
```
4ï¸âƒ£ Activate Environment
```bash
conda activate ai_blog_env
```
3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

## ğŸ“¥ Download LLaMA 2 Model
Download a compatible GGML / GGUF model and place it inside the model/ folder.
Example:
```bash
model/llama-2-7b-chat.ggmlv3.q8_0.bin
```
âš ï¸ Make sure your system has enough RAM (8GB+ recommended).

## â–¶ï¸ Run the Application
```bash
streamlit run app.py
```
Open browser:
```bash
http://localhost:8501
```

## ğŸ§ª How It Works
1. User enters blog topic
2. Selects word limit and target audience
3. Prompt is dynamically created using LangChain
4. LLaMA 2 model generates blog locally
5. Output is displayed in Streamlit UI

## ğŸ“Œ Example Prompt
Write a blog for a Data Scientist job profile on the topic "Generative AI" within 500 words.

## ğŸ”® Future Enhancements
- âœ… RAG (Retrieval-Augmented Generation)
- âœ… Vector database integration (FAISS / ChromaDB)
- âœ… Multi-model selection
- âœ… Download blog as .txt or .md
- âœ… FastAPI backend

## ğŸ§‘â€ğŸ’» Author
Chintan Dabhi
MCA Student | AI & ML Enthusiast

## â­ Support
If you find this project useful, please â­ star the repository and share it!

## ğŸ“œ License
This project is licensed under the MIT License.
